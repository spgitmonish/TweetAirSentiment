{
    "collab_server" : "",
    "contents" : "```{r, warning=FALSE}\nlibrary(mlbench)\nlibrary(caret)\nlibrary(ggplot2)\n```\n\n## Create a Validation Dataset\n```{r, warning=FALSE}\ndata(BreastCancer)\n\n# Split data set with 80% for training and 20% for validation\nvalidationIndex <- createDataPartition(BreastCancer$Class, p=0.80, list=FALSE)\n\n# Select 20% of the data for validation\nvalidation <- BreastCancer[-validationIndex,]\n\n# Use the remaining 80% of the data for training and testing the models\ndataset <- BreastCancer[validationIndex,]\n```\n\n## Analyze Data\n```{r, warning=FALSE}\n# Dimensions of the data\ndim(dataset)\n\n# Inspect the elements in the dataset\nhead(dataset)\n\n# Look at the class types\nsapply(dataset, class)\n\n# Remove the redundant variable Id\ndataset <- dataset[,-1]\nvalidation <- validation[,-1]\n\n# Convert independent variables values to numeric\nfor(i in 1:9){\n  dataset[,i] <- as.numeric(as.character(dataset[,i]))\n  validation[,i] <- as.numeric(as.character(validation[,i]))\n}\n\n# Summarize the data after transformation\nsummary(dataset)\n\n# Look at the class distribution of the dependent variable\ncbind(freq=table(dataset$Class), percentage=prop.table(table(dataset$Class))*100)\n\n# There are N/As in the Bare.nuclei variable, so we will have to consider only the complete cases\ncomplete_cases <- complete.cases(dataset)\n\n# Summarize the correlations between the variables\ncor(dataset[complete_cases, 1:9])\n```\n\n## Data visualizations\n```{r, warning=FALSE}\n# Histograms of the numeric variable\npar(mfrow=c(3,3))\nfor(i in 1:9){\n  hist(dataset[,i], main=names(dataset)[i])\n}\n\n# Density plots for complete cases\npar(mfrow=c(3,3))\ncomplete_cases <- complete.cases(dataset)\nfor(i in 1:9){\n  plot(density(dataset[complete_cases,i]), main=names(dataset)[i])\n}\n\n# Box and whisker plots to understand distributions better\npar(mfrow=c(3,3))\nfor(i in 1:9) {\n  boxplot(dataset[,i], main=names(dataset)[i])\n}\n\n# Add some jitter to make the scatter plots useful, seperate by class\njittered_x <- sapply(dataset[,1:9], jitter)\npairs(jittered_x, names(dataset[,1:9]), col=dataset$Class)\n\n# Bar plots of each variable seperated by class\n# bar plots of each variable by class\npar(mfrow=c(3,3))\nfor(i in 1:9) {\n  barplot(table(dataset$Class,dataset[,i]), main=names(dataset)[i],\n          legend.text=unique(dataset$Class))\n}\n```\n\n## Algorithm selections\n```{r, warning=FALSE}\n# 10 fold cross validation with 3 repeats\ntrainControl <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n\n# Use Accuracy and Kappa metrics for measuring performance\nmetric <- \"Accuracy\"\n\n# use the same seed across to make sure the same data splits are used\n# Linear Regression\nset.seed(7)\nfit.glm <- train(Class~., data=dataset, method=\"glm\", metric=metric, trControl=trainControl)\n\n# Linear Discriminant Analysis\nset.seed(7)\nfit.lda <- train(Class~., data=dataset, method=\"lda\", metric=metric, trControl=trainControl)\n\n# GLMNET(Regularized Logistic Regression)\nset.seed(7)\nfit.glmnet <- train(Class~., data=dataset, method=\"glmnet\", metric=metric, trControl=trainControl)\n\n# kNN\nset.seed(7)\nfit.knn <- train(Class~., data=dataset, method=\"knn\", metric=metric, trControl=trainControl)\n\n# CART(Classification and Regression Trees)\nset.seed(7)\nfit.cart <- train(Class~., data=dataset, method=\"rpart\", metric=metric, trControl=trainControl)\n\n# Naive Bayes\nset.seed(7)\nfit.nb <- train(Class~., data=dataset, method=\"nb\", metric=metric, trControl=trainControl)\n\n# SVM with Radial Bias as Kernel\nset.seed(7)\nfit.svm <- train(Class~., data=dataset, method=\"svmRadial\", metric=metric, trControl=trainControl)\n\n# Compare algorithms\nresults <- resamples(list(LG=fit.glm, LDA=fit.lda, GLMNET=fit.glmnet, \n                          KNN=fit.knn, CART=fit.cart, NB=fit.nb, SVM=fit.svm))\nsummary(results)\ndotplot(results)\n\n# Apply Box-Cox transformations to normalize data\n# Linear Regression\nset.seed(7)\nfit.glm <- train(Class~., data=dataset, method=\"glm\", metric=metric, \n                 preProc=c(\"BoxCox\"), trControl=trainControl)\n\n# Linear Discriminant Analysis\nset.seed(7)\nfit.lda <- train(Class~., data=dataset, method=\"lda\", metric=metric, \n                 preProc=c(\"BoxCox\"), trControl=trainControl)\n\n# GLMNET(Regularized Logistic Regression)\nset.seed(7)\nfit.glmnet <- train(Class~., data=dataset, method=\"glmnet\", metric=metric, \n                    preProc=c(\"BoxCox\"), trControl=trainControl)\n\n# kNN\nset.seed(7)\nfit.knn <- train(Class~., data=dataset, method=\"knn\", metric=metric, \n                 preProc=c(\"BoxCox\"), trControl=trainControl)\n\n# CART(Classification and Regression Trees)\nset.seed(7)\nfit.cart <- train(Class~., data=dataset, method=\"rpart\", metric=metric, \n                  preProc=c(\"BoxCox\"), trControl=trainControl)\n\n# Naive Bayes\nset.seed(7)\nfit.nb <- train(Class~., data=dataset, method=\"nb\", metric=metric, \n                preProc=c(\"BoxCox\"), trControl=trainControl)\n\n# SVM with Radial Bias as Kernel\nset.seed(7)\nfit.svm <- train(Class~., data=dataset, method=\"svmRadial\", metric=metric, \n                 preProc=c(\"BoxCox\"), trControl=trainControl)\n\n# Compare algorithms\nresults <- resamples(list(LG=fit.glm, LDA=fit.lda, GLMNET=fit.glmnet, \n                          KNN=fit.knn, CART=fit.cart, NB=fit.nb, SVM=fit.svm))\nsummary(results)\ndotplot(results)\n```\n\n## Tuning algorithms\n```{r, warning=FALSE}\ntrainControl <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\nmetric <- \"Accuracy\"\n\n# Tune SVM\nset.seed(7)\ngrid <- expand.grid(.sigma=c(0.025, 0.05, 0.1, 0.15), .C=seq(1, 10, by=1))\nfit.svm <- train(Class~., data=dataset, method=\"svmRadial\", metric=metric, \n                 tuneGrid=grid, preProc=c(\"BoxCox\"), trControl=trainControl)\nprint(fit.svm)\nplot(fit.svm)\n\n# Tune kNN\nset.seed(7)\ngrid <- expand.grid(.k=seq(1, 20, by=1))\nfit.knn <- train(Class~., data=dataset, method=\"knn\", metric=metric, \n                 tuneGrid=grid, preProc=c(\"BoxCox\"), trControl=trainControl)\nprint(fit.knn)\nplot(fit.knn)\n```\n\n## Boosting and Bagging Ensemble Algorithms\n```{r, warning=FALSE}\n# 10-fold cross validation with 3 repeats\ntrainControl <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n\nmetric <- \"Accuracy\"\n# Bagged CART\nset.seed(7)\nfit.treebag <- train(Class~., data=dataset, method=\"treebag\", metric=metric,\n                     trControl=trainControl)\n\n# Random Forest\nset.seed(7)\nfit.rf <- train(Class~., data=dataset, method=\"rf\", metric=metric, preProc=c(\"BoxCox\"),\n                trControl=trainControl)\n\n# Stochastic Gradient Boosting\nset.seed(7)\nfit.gbm <- train(Class~., data=dataset, method=\"gbm\", metric=metric, preProc=c(\"BoxCox\"),\n                 trControl=trainControl, verbose=FALSE)\n\n# C5.0\nset.seed(7)\nfit.c50 <- train(Class~., data=dataset, method=\"C5.0\", metric=metric, preProc=c(\"BoxCox\"),\n                 trControl=trainControl)\n\n# Compare results\nensembleResults <- resamples(list(BAG=fit.treebag, RF=fit.rf, GBM=fit.gbm, C50=fit.c50))\n\nsummary(ensembleResults)\ndotplot(ensembleResults)\n```\n\n## Finalize model\n```{r, warning=FALSE}\n# Remove missing values\nset.seed(7)\ndatasetNoMissing <- dataset[complete.cases(dataset),]\nx <- datasetNoMissing[,1:9]\n\n# Apply transform\npreprocessParams <- preProcess(x, method=c(\"BoxCox\"))\n\n# Get new predicted values based on the transform\npredictedResults <- predict(preprocessParams, x)\nx <- predict(preprocessParams, x)\n\n# Prepare the validation dataset\nset.seed(7)\n\n# Remove missing values (not allowed in this implementation of knn)\nvalidation <- validation[complete.cases(validation),]\n\n# Transform the validation dataset\nvalidationX <- predict(preprocessParams, validation[,1:9])\n\n# make predictions\nset.seed(7)\npredictions <- knn3Train(x, validationX, datasetNoMissing$Class, k=9, prob=FALSE)\nconfusionMatrix(predictions, validation$Class)\n```",
    "created" : 1456172996080.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4156137584",
    "id" : "B2560006",
    "lastKnownWriteTime" : 1456165404,
    "last_content_update" : 1456165404,
    "path" : "C:/Users/443615/Downloads/Project 1/Project 1.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}