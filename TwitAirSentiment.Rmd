```{r, warning=FALSE}
library(mlbench)
library(caret)
library(ggplot2)
library(tm)
library(wordcloud)
library(SparseM)
library(e1071)
library(RTextTools)
```

## Analyze Data, clean up if necessary
```{r, warning=FALSE}
dataset <- read.csv("Tweets.csv")

# Look at the dimensions of the dataset
dim(dataset)

# Look at the first view variables of the dataset
head(dataset)

# Class of each of the variables
sapply(dataset, class)

# Remove the "tweet_id", "tweet_created", "tweet_coord", airline_sentiment_gold"" & "negativereason_gold" variables
# These variables don't have enough values or don't add any value to the analysis
dataset <- subset(dataset, select = -c(tweet_id, tweet_created, tweet_coord, 
                                       airline_sentiment_gold, negativereason_gold)) 

# Summary of the data
summary(dataset)

# Look at the class distribution of the dependent variable
cbind(freq=table(dataset$airline_sentiment), percentage=prop.table(table(dataset$airline_sentiment))*100)
```

After looking at the data it is clear that the sentiment is Negative: 62.6%, Neutral: 21.2% & Positive: 16.1%. Not good for airlines unfortunately. This is just from the initial analysis.

## Data Visualization
```{r, echo=FALSE}
# Bar plot of each airline seperated by sentiment
ggplot(data = dataset, aes(x = airline, fill = airline_sentiment)) +
  geom_bar(stat = "count")

# Bar plot of each retweet count seperated by airline
ggplot(data = dataset, aes(x = retweet_count)) +
  facet_grid(~airline) + 
  geom_bar(stat = "count") +
  scale_x_continuous(limits = c(0, 10), breaks = 0:10) +
  scale_y_continuous(limits = c(0, 300))
```

Things to note from the previous visualization section:
1. The negative sentiment is very obvious when visualized
2. United, US Airways, American are the top 3 in negative tweets. 
3. Virgin Atlantic is almost uniformly divided in sentiment
4. The retweet count is the highest for United
5. I chose to ignore the other numeric fields for any data visualization as I am focused more on Textual Analysis and predictions. 

## Text analysis for the actual tweet
```{r, warning=FALSE}
# Concatenate vectors after converting to characters(collapse says we want to collapse elements
# of the vector rather than pasting vectors together)
tweet_text <- paste(dataset$text, collapse = " ")

# Create a vector source from the previously created vector
tweet_source <- VectorSource(tweet_text)

# Create a corpus(a collection of text)
corpus <- Corpus(tweet_source)

# Clean text: Convert to lower case, remove punctuation, strip white space &
#             remove stop words(common words)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("en"))

# Create the document term matrix from the corpus
tweet_dtm <- DocumentTermMatrix(corpus)
tweet_dtm <- as.matrix(tweet_dtm)

# Take the column sums of this matrix 
frequency <- colSums(tweet_dtm)

# Sort by the most frequently used words
frequency <- sort(frequency, decreasing = TRUE)

# Get a list of the words
words <- names(frequency)

# Plot the top 100 words in our cloud
wordcloud(words[1:100], frequency[1:100])

# After looking at the word cloud remove the words which represent airlines.
# These words represent the twitter handles
corpus <- tm_map(corpus, removeWords, c("americanair", "virginamerica", "southwestair",
                                            "jetblue", "united", "usairways"))

# Recreate the word cloud after removal
tweet_dtm <- DocumentTermMatrix(corpus)
tweet_dtm <- as.matrix(tweet_dtm)
frequency <- colSums(tweet_dtm)
frequency <- sort(frequency, decreasing = TRUE)
words <- names(frequency)
wordcloud(words[1:100], frequency[1:100])
```

From the word cloud for the "text" variable we see that "Flight" is the most often used word. The other words which stand out are "get", "cancelled", "now", "customer service", "thanks" to name a few

## Text analysis of the negative reason
```{r, warning=FALSE}
# Concatenate vectors after converting to characters(collapse says we want to collapse elements
# of the vector rather than pasting vectors together)
reason_text <- paste(dataset$negativereason, collapse = " ")

# Create a vector source from the previously created vector
reason_source <- VectorSource(reason_text)

# Create a corpus(a collection of text)
reason_corpus <- Corpus(reason_source)

# Clean text: Convert to lower case, remove punctuation, strip white space &
#             remove stop words(common words)
reason_corpus <- tm_map(reason_corpus, content_transformer(tolower))
reason_corpus <- tm_map(reason_corpus, removePunctuation)
reason_corpus <- tm_map(reason_corpus, stripWhitespace)
reason_corpus <- tm_map(reason_corpus, removeWords, stopwords("en"))

# Create the document term matrix from the corpus
reason_dtm <- DocumentTermMatrix(reason_corpus)
reason_dtm <- as.matrix(reason_dtm)

# Take the column sums of this matrix 
reason_frequency <- colSums(reason_dtm)

# Sort by the most frequently used words
reason_frequency <- sort(reason_frequency, decreasing = TRUE)

# Get a list of the words
reason_words <- names(reason_frequency)

# Plot the top 100 words in our cloud
wordcloud(reason_words, reason_frequency)
```

From the word cloud of the "negativereason" variable it is very obvious what words are used when 
this field was used to report the reasons. The words displayed in the cloud are not surprising when
customers face issues with airlines. 

## Create a Validation Dataset
```{r, warning=FALSE}
# Split data set with 80% for training and 20% for validation
set.seed(7)
validationIndex <- createDataPartition(dataset$airline_sentiment, p = 0.80, list = FALSE)

# Select 20% of the data for validation
validation <- dataset[-validationIndex,]

# Use the remaining 80% of the data for training and testing the models
dataset <- dataset[validationIndex,]
```

## Naive Bayes Text Classification
```{r, warning=FALSE}
# Convert the training and validation data sets to data frames
traindf <- as.data.frame(dataset)
testdf <- as.data.frame(validation)

# Create a corpus for training and validation data frames
text_trainvector <- as.vector(traindf$text)
text_testvector <- as.vector(testdf$text)

# Create source for the vectors
text_trainsource <- VectorSource(text_trainvector)
text_testsource <- VectorSource(text_testvector)

# Create corpus for the data
text_traincorpus <- Corpus(text_trainsource)
text_testcorpus <- Corpus(text_testsource)

# Repeat the steps from the previous section(cleaning)
text_traincorpus <- tm_map(text_traincorpus, content_transformer(tolower))
text_traincorpus <- tm_map(text_traincorpus, removePunctuation)
text_traincorpus <- tm_map(text_traincorpus, stripWhitespace)
text_traincorpus <- tm_map(text_traincorpus, removeWords, stopwords("en"))
text_traincorpus <- tm_map(text_traincorpus, removeWords, 
                           c("americanair", "virginamerica", "southwestair",
                             "jetblue", "united", "usairways"))

text_testcorpus <- tm_map(text_testcorpus, content_transformer(tolower))
text_testcorpus <- tm_map(text_testcorpus, removePunctuation)
text_testcorpus <- tm_map(text_testcorpus, stripWhitespace)
text_testcorpus <- tm_map(text_testcorpus, removeWords, stopwords("en"))
text_testcorpus <- tm_map(text_testcorpus, removeWords, c("americanair", "virginamerica",
                                                          "southwestair","jetblue", "united",
                                                          "usairways"))

# Create the term document matrix
text_trainmatrix <- t(TermDocumentMatrix(text_traincorpus))
text_testmatrix <- t(TermDocumentMatrix(text_testcorpus))

# Using Naive Bayes and airline_sentiment as the class variable train the classifier
set.seed(7)
text_modelnb <- naiveBayes(as.matrix(text_trainmatrix), 
                           as.factor(traindf$airline_sentiment))

# Predict!
text_nbResults <- predict(text_modelnb, as.matrix(text_testmatrix))

# Compare the results
confusionMatrix(text_nbResults, testdf$airline_sentiment)
```

The results from the Naive Bayes Classification looks pretty bad using the "text" variable! Let's try the 
"negativereason" variable next

## Naive Bayes Negative Reason Classification
```{r, warning=FALSE}
# Create a corpus for training and validation data frames
reason_trainvector <- as.vector(traindf$negativereason)
reason_testvector <- as.vector(testdf$negativereason)

# Create source for the vectors
reason_trainsource <- VectorSource(reason_trainvector)
reason_testsource <- VectorSource(reason_testvector)

# Create corpus for the data
reason_traincorpus <- Corpus(reason_trainsource)
reason_testcorpus <- Corpus(reason_testsource)

# Repeat the steps from the previous section(cleaning)
reason_traincorpus <- tm_map(reason_traincorpus, content_transformer(tolower))
reason_traincorpus <- tm_map(reason_traincorpus, removePunctuation)
reason_traincorpus <- tm_map(reason_traincorpus, stripWhitespace)
reason_traincorpus <- tm_map(reason_traincorpus, removeWords, stopwords("en"))

reason_testcorpus <- tm_map(reason_testcorpus, content_transformer(tolower))
reason_testcorpus <- tm_map(reason_testcorpus, removePunctuation)
reason_testcorpus <- tm_map(reason_testcorpus, stripWhitespace)
reason_testcorpus <- tm_map(reason_testcorpus, removeWords, stopwords("en"))

# Create the term document matrix
reason_trainmatrix <- t(TermDocumentMatrix(reason_traincorpus))
reason_testmatrix <- t(TermDocumentMatrix(reason_testcorpus))

# Using Naive Bayes and airline_sentiment as the class variable train the classifier
set.seed(7)
reason_modelnb <- naiveBayes(as.matrix(reason_trainmatrix), traindf$airline_sentiment)

# Predict!
reason_nbResults <- predict(reason_modelnb, as.matrix(reason_testmatrix))

# Compare the results
confusionMatrix(reason_nbResults, testdf$airline_sentiment)
```

Not much of a difference again when using the "negativereason" variable as the independent variable

## Try RTextTools library and SVM as the algorithm
```{r, warning=FALSE}
# Create a Document Term Matrix
dtMatrix <- create_matrix(traindf$text, language = "english", 
                          removeNumbers = TRUE, removeStopwords = TRUE,
                          minWordLength = 3, removePunctuation = TRUE,
                          stripWhitespace = TRUE, toLower = TRUE,
                          weighting = tm::weightTfIdf)

# Configure the training data
container <- create_container(dtMatrix, traindf$airline_sentiment, 
                              trainSize=1:11714, virgin=FALSE)

# Train a SVM Model
model <- train_model(container, "SVM", kernel = "radial", cost = 10, cross = 10)

# Create a prediction document term matrix
predMatrix <- create_matrix(testdf$text, originalMatrix = dtMatrix, 
                            removeNumbers = TRUE, removeStopwords = TRUE,
                            minWordLength = 3, removePunctuation = TRUE,
                            stripWhitespace = TRUE, toLower = TRUE,
                            weighting = tm::weightTfIdf)

# Configure the test data
testcontainer <- create_container(predMatrix, testdf$airline_sentiment, 
                                  trainSize = 1:2926, virgin = FALSE)

# Predict!
results <- classify_model(testcontainer, model)

# Compare the results
confusionMatrix(results$SVM_LABEL, testdf$airline_sentiment)
```

The accuracy of classification improves when using SVM for classification!

## Combine the "text" variable and the "negativereason" variable and try SVM
```{r, warning=FALSE}
# Create a Document Term Matrix for the "text" variable
text_dtMatrix <- create_matrix(traindf$text, language = "english", 
                               removeNumbers = TRUE, removeStopwords = TRUE,
                               minWordLength = 3, removePunctuation = TRUE,
                               stripWhitespace = TRUE, toLower = TRUE,
                               weighting = tm::weightTfIdf)

# Create a Document Term Matrix for the "negativereason" variable
reason_dtMatrix <- create_matrix(traindf$negativereason, language = "english", 
                                 removeNumbers = TRUE, removeStopwords = TRUE,
                                 minWordLength = 3, removePunctuation = TRUE,
                                 stripWhitespace = TRUE, toLower = TRUE, 
                                 weighting = tm::weightTfIdf)

# Combine the two matrices
combined_dtMatrix <- cbind(text_dtMatrix, reason_dtMatrix)
  
# Configure the training data
combined_container <- create_container(combined_dtMatrix, traindf$airline_sentiment,
                                       trainSize = 1:11714, virgin = FALSE)

# Train a SVM Model
set.seed(7)
modelsvm <- train_model(combined_container, "SVM", kernel = "radial", cost = 10, cross = 10)

# Create a prediction Document Term Matrix for the "text" variable
text_predMatrix <- create_matrix(testdf$text, language = "english", 
                                 originalMatrix = text_dtMatrix,
                                 removeNumbers = TRUE, removeStopwords = TRUE,
                                 minWordLength = 3, removePunctuation = TRUE,
                                 stripWhitespace = TRUE, toLower = TRUE,
                                 weighting = tm::weightTfIdf)

# Create a prediction Document Term Matrix for the "negativereason" variable
reason_predMatrix <- create_matrix(testdf$negativereason, language = "english", 
                                   originalMatrix = reason_dtMatrix, 
                                   removeNumbers = TRUE, removeStopwords = TRUE,
                                   minWordLength = 3, removePunctuation = TRUE,
                                   stripWhitespace = TRUE, toLower = TRUE,
                                   weighting = tm::weightTfIdf)

# Combine the two matrices
combined_predMatrix <- cbind(text_predMatrix, reason_predMatrix)

# Configure the test data
combined_testcontainer <- create_container(combined_predMatrix, testdf$airline_sentiment, 
                                           trainSize = 1:2926, virgin = FALSE)

# Predict!
combined_results_svm <- classify_model(combined_testcontainer, modelsvm)

# Compare the results
confusionMatrix(combined_results_svm$SVM_LABEL, testdf$airline_sentiment)
```

After combining the matrices the accuracy shoots up! The Kappa looks pretty good as well. Let's try a couple of 
other algorithms to see if our accuracy improves. 

```{r, warning=FALSE}
# Random Forest
set.seed(7)
modelrf <- train_model(combined_container, "RF", ntree = 3, cross = 10)
combined_results_rf <- classify_model(combined_testcontainer, modelrf)
confusionMatrix(combined_results_rf$FORESTS_LABEL, testdf$airline_sentiment)

# GLMNET
set.seed(7)
modelglmnet <- train_model(combined_container, "GLMNET", cross = 10)
combined_results_glmnet <- classify_model(combined_testcontainer, modelglmnet)
confusionMatrix(combined_results_glmnet$GLMNET_LABEL, testdf$airline_sentiment)

# TREE
set.seed(7)
modeltree <- train_model(combined_container, "TREE", ntree = 3, cross = 10)
combined_results_tree <- classify_model(combined_testcontainer, modeltree)
confusionMatrix(combined_results_tree$TREE_LABEL, testdf$airline_sentiment)

# Boosting
set.seed(7)
modelboosting <- train_model(combined_container, "BOOSTING", cross = 10)
combined_results_boosting <- classify_model(combined_testcontainer, modelboosting)
confusionMatrix(combined_results_boosting$LOGITBOOST_LABEL, testdf$airline_sentiment)
```