```{r, warning=FALSE}
library(mlbench)
library(caret)
library(ggplot2)
library(tm)
library(wordcloud)
library(SparseM)
library(e1071)
```

## Analyze Data, clean up if necessary
```{r, warning=FALSE}
dataset <- read.csv("Tweets.csv")

# Look at the dimensions of the dataset
dim(dataset)

# Look at the first view variables of the dataset
head(dataset)

# Class of each of the variables
sapply(dataset, class)

# Remove the "tweet_id", "tweet_created", "tweet_coord", airline_sentiment_gold"" & "negativereason_gold" variables
# These variables don't have enough values or don't add any value to the analysis
dataset <- subset(dataset, select = -c(tweet_id, tweet_created, tweet_coord, 
                                       airline_sentiment_gold, negativereason_gold)) 

# Summary of the data
summary(dataset)

# Look at the class distribution of the dependent variable
cbind(freq=table(dataset$airline_sentiment), percentage=prop.table(table(dataset$airline_sentiment))*100)
```

After looking at the data it is clear that the sentiment is Negative: 62.6%, Neutral: 21.2% & Positive: 16.1%. Not good for airlines unfortunately. This is just from the initial analysis.

## Data Visualization
```{r, echo=FALSE}
# Bar plot of each airline seperated by sentiment
ggplot(data = dataset, aes(x = airline, fill = airline_sentiment)) +
  geom_bar(stat = "count")

# Look at the distribution of airline_sentiment_confidence
ggplot(data = dataset, aes(x = airline_sentiment_confidence, fill = airline_sentiment)) + 
  geom_histogram(bins = 50) + 
  facet_grid(airline_sentiment ~ airline, scales = "free_y") + 
  scale_x_continuous(limits = c(0, 1)) +
  scale_y_continuous(limits = c(0, 80))

# Look at the distribution of airline_sentiment_confidence
ggplot(data = dataset, aes(x = airline_sentiment_confidence, fill = airline_sentiment)) + 
  geom_histogram(bins = 50) + 
  facet_grid(airline_sentiment ~ airline, scales = "free_y") + 
  scale_x_continuous(limits = c(0, 1)) +
  scale_y_continuous(limits = c(0, 80))
```

## Text analysis
```{r, warning=FALSE}
# Concatenate vectors after converting to characters(collapse says we want to collapse elements
# of the vector rather than pasting vectors together)
tweet_text <- paste(dataset$text, collapse = " ")

# Create a vector source from the previously created vector
tweet_source <- VectorSource(tweet_text)

# Create a corpus(a collection of text)
corpus <- Corpus(tweet_source)

# Clean text: Convert to lower case, remove punctuation, strip white space &
#             remove stop words(common words)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("en"))

# Create the document term matrix from the corpus
tweet_dtm <- DocumentTermMatrix(corpus)
tweet_dtm <- as.matrix(tweet_dtm)

# Take the column sums of this matrix 
frequency <- colSums(tweet_dtm)

# Sort by the most frequently used words
frequency <- sort(frequency, decreasing = TRUE)

# Get a list of the words
words <- names(frequency)

# Plot the top 100 words in our cloud
wordcloud(words[1:100], frequency[1:100])

# After looking at the word cloud remove the words which represent airlines.
# These words represent the twitter handles
corpus <- tm_map(corpus, removeWords, c("americanair", "virginamerica", "southwestair",
                                            "jetblue", "united", "usairways"))

# Recreate the word cloud after removal
tweet_dtm <- DocumentTermMatrix(corpus)
tweet_dtm <- as.matrix(tweet_dtm)
frequency <- colSums(tweet_dtm)
frequency <- sort(frequency, decreasing = TRUE)
words <- names(frequency)
wordcloud(words[1:100], frequency[1:100])
```

## Create a Validation Dataset
```{r, warning=FALSE}
# Split data set with 80% for training and 20% for validation
set.seed(7)
validationIndex <- createDataPartition(dataset$airline_sentiment, p = 0.80, list = FALSE)

# Select 20% of the data for validation
validation <- dataset[-validationIndex,]

# Use the remaining 80% of the data for training and testing the models
dataset <- dataset[validationIndex,]
```

## Naive Bayes Text Classification
```{r, warning=FALSE}
# Convert the training and validation data sets to data frames
traindf <- as.data.frame(dataset)
testdf <- as.data.frame(validation)

# Create a corpus for training and validation data frames
trainvector <- as.vector(traindf$text)
testvector <- as.vector(testdf$text)

# Create source for the vectors
trainsource <- VectorSource(trainvector)
testsource <- VectorSource(testvector)

# Create corpus for the data
traincorpus <- Corpus(trainsource)
testcorpus <- Corpus(testsource)

# Repeat the steps from the previous section(cleaning)
traincorpus <- tm_map(traincorpus, content_transformer(tolower))
traincorpus <- tm_map(traincorpus, removePunctuation)
traincorpus <- tm_map(traincorpus, stripWhitespace)
traincorpus <- tm_map(traincorpus, removeWords, stopwords("en"))
traincorpus <- tm_map(traincorpus, removeWords, c("americanair", "virginamerica", "southwestair",
                                                  "jetblue", "united", "usairways"))

testcorpus <- tm_map(testcorpus, content_transformer(tolower))
testcorpus <- tm_map(testcorpus, removePunctuation)
testcorpus <- tm_map(testcorpus, stripWhitespace)
testcorpus <- tm_map(testcorpus, removeWords, stopwords("en"))
testcorpus <- tm_map(testcorpus, removeWords, c("americanair", "virginamerica", "southwestair",
                                                "jetblue", "united", "usairways"))

# Create the term document matrix
trainmatrix <- t(TermDocumentMatrix(traincorpus))
testmatrix <- t(TermDocumentMatrix(testcorpus))

# Using Naive Bayes and a airline_sentiment as the class variable train the classifier
modelnb <- naiveBayes(as.matrix(trainmatrix), as.factor(traindf$airline_sentiment))
modelnb1 <- naiveBayes(as.matrix(trainmatrix), as.factor(traindf$airline_sentiment), laplace = 3)

# Predict!
nbResults <- predict(modelnb, as.matrix(testmatrix))
confusionMatrix(nbResults, testdf$airline_sentiment)
nbResults1 <- predict(modelnb1, as.matrix(testmatrix))
confusionMatrix(nbResults1, testdf$airline_sentiment)

```